{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b745cf72-4faf-4e63-8058-ec4c06e5f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c340dc-e5fa-49b2-9078-190e8f43bbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bill/dev/taskllm/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import csv\n",
    "from enum import Enum\n",
    "\n",
    "from loguru import logger\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from taskllm.optimizer.data import DataSet, Row\n",
    "from taskllm.optimizer.methods import BanditTrainer, BayesianTrainer\n",
    "from taskllm.optimizer.prompt.meta import PromptMode\n",
    "\n",
    "# logger.remove()  # remove the old handler. Else, the old one will work (and continue printing DEBUG logs) along with the new handler added below'\n",
    "# logger.add(sys.stdout, level=\"TRACE\")  # add a new handler which has INFO as the default\n",
    "\n",
    "\n",
    "class Ratings(Enum):\n",
    "    ONE = \"1\"\n",
    "    TWO = \"2\"\n",
    "    THREE = \"3\"\n",
    "    FOUR = \"4\"\n",
    "    FIVE = \"5\"\n",
    "    NA = \"N/A\"\n",
    "\n",
    "\n",
    "class StarbucksReviewRating(BaseModel):\n",
    "    rating: Ratings\n",
    "\n",
    "\n",
    "def sentiment_scoring_function(\n",
    "    row: Row[StarbucksReviewRating], output: StarbucksReviewRating | None\n",
    ") -> float:\n",
    "    if output is None:\n",
    "        return -10\n",
    "    if not row.expected_output:\n",
    "        return 0\n",
    "    logger.trace(f\"Expected: {row.expected_output.rating}, Output: {output.rating}\")\n",
    "    if row.expected_output.rating == output.rating:\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def load_file_as_dataset(path: str) -> DataSet:\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            rating = StarbucksReviewRating(rating=Ratings(row[\"Rating\"]))\n",
    "            rows.append(\n",
    "                Row.create(\n",
    "                    input_dictionary={\n",
    "                        \"review\": row[\"Review\"],\n",
    "                        \"name\": row[\"name\"],\n",
    "                        \"location\": row[\"location\"],\n",
    "                        \"date\": row[\"Date\"],\n",
    "                    },\n",
    "                    output=rating,\n",
    "                )\n",
    "            )\n",
    "    return DataSet(rows=rows[:50], name=\"starbucks_reviews\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa6f3b0-6885-44a5-aab7-60399f18e058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 20:57:11.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m208\u001b[0m - \u001b[1mUsing CPU for Pyro/Torch computations\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:11.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m242\u001b[0m - \u001b[1mAll rows: 50\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:11.871\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m721\u001b[0m - \u001b[34m\u001b[1mBayesianTrainer initialized\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"./starbucks_reviews.csv\"\n",
    "dataset = load_file_as_dataset(csv_path)\n",
    "trainer = BayesianTrainer(\n",
    "    all_rows=dataset,\n",
    "    task_guidance=\"determine the rating of this review\",\n",
    "    keys=[\"review\", \"name\", \"location\", \"date\"],\n",
    "    expected_output_type=StarbucksReviewRating,\n",
    "    scoring_function=sentiment_scoring_function,\n",
    "    num_iterations=2,  # Start with fewer iterations for testing\n",
    "    candidates_per_iteration=2,  # Start with fewer candidates for testing\n",
    "    prompt_mode=PromptMode.SIMPLE,\n",
    "    models=[\n",
    "        \"anthropic/claude-3-haiku-20240307\",\n",
    "        \"openai/gpt-4.1-nano-2025-04-14\",\n",
    "        \"openai/gpt-4.1-mini-2025-04-14\",\n",
    "        \"groq/gemma2-9b-it\",\n",
    "        \"groq/qwen-qwq-32b\"\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197101ec-6e1c-4750-a281-a7772b0e376f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 20:57:11.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m725\u001b[0m - \u001b[1mStarting Bayesian optimization with Pyro: 2 iterations, 2 candidates/iter.\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:11.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m731\u001b[0m - \u001b[1mPhase 1: Generating and evaluating initial candidates...\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:11.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "Use plain language in the prompt you write...\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:14.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "Make the prompt you write as simple as possible...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a review evaluator. Your task is to analyze the review provided and assign a star rating based on its content. Take into account the tone, details, and overall sentiment expressed in the review.\n",
      "\n",
      "Here are the details of the review:\n",
      "- Review: {{ review }}\n",
      "- Name of the reviewer: {{ name }}\n",
      "- Location of the reviewer: {{ location }}\n",
      "- Date of the review: {{ date }}\n",
      "\n",
      "After your analysis, please clearly state the star rating from 1 to 5, with 1 being poor and 5 being excellent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 20:57:16.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m754\u001b[0m - \u001b[1mGenerated 2 initial candidate prompts.\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:16.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m280\u001b[0m - \u001b[1mRunning for prompt You are a review evaluator. Your task is to analyze the review provided and assign a star rating bas... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:16.325\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:16.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m280\u001b[0m - \u001b[1mRunning for prompt You are a review rating expert. Analyze the review provided by the user and assign it a rating betwe... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:16.326\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a review rating expert. Analyze the review provided by the user and assign it a rating between 1 and 5 based on its content. Consider the tone, content quality, and overall impression. The review details are as follows: Review: {{ review }}; Name: {{ name }}; Location: {{ location }}; Date: {{ date }}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 20:57:56.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m766\u001b[0m - \u001b[1mFitting initial surrogate model\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:56.675\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m267\u001b[0m - \u001b[32m\u001b[1mExtracted features for 2 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:56.676\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:56.677\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:56.714\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:56.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 31.0000, Correct: 31, Incorrect: 9, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:56.715\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:56.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 30.0000, Correct: 30, Incorrect: 10, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:56.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mFitting GP surrogate model with 2 data points\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:57.338\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 0/1000, Loss: 7.8156\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:57.412\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 100/1000, Loss: 3.7798\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:57.479\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 200/1000, Loss: 3.3845\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:57.550\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 300/1000, Loss: 3.1347\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:57.621\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 400/1000, Loss: 2.9403\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:57.696\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 500/1000, Loss: 2.8667\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:57.771\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 600/1000, Loss: 2.8488\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:57.874\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 700/1000, Loss: 2.8434\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:57.951\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 800/1000, Loss: 2.8411\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.036\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 900/1000, Loss: 2.8400\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m318\u001b[0m - \u001b[1mSuccessfully fit Pyro GP model with final loss: 2.8394\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m770\u001b[0m - \u001b[1mPhase 2: Starting 1 optimization iterations...\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m778\u001b[0m - \u001b[1mIteration 2/2\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m672\u001b[0m - \u001b[1mSelecting best prompt from 2 prompts using 40 evaluation rows\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m123\u001b[0m - \u001b[1mSelecting best prompt from 2 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.121\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.121\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.150\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 31.0000, Correct: 31, Incorrect: 9, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.151\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 30.0000, Correct: 30, Incorrect: 10, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.152\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.167\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 31.0000, Correct: 31, Incorrect: 9, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mCurrent best score: 31.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_next_prompts\u001b[0m:\u001b[36m484\u001b[0m - \u001b[1mCalculating best score from history\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m649\u001b[0m - \u001b[1mNo rows provided, using 2 prompts for evaluation\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.171\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mpredict_performance\u001b[0m:\u001b[36m358\u001b[0m - \u001b[34m\u001b[1mPredicted performance: mean=30.8827, std=0.2343\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.173\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mpredict_performance\u001b[0m:\u001b[36m358\u001b[0m - \u001b[34m\u001b[1mPredicted performance: mean=30.1117, std=0.2248\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1mSelected best prompt using surrogate model with predicted score: 30.8827\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.174\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.189\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_next_prompts\u001b[0m:\u001b[36m522\u001b[0m - \u001b[1mGenerating candidate pool for Bayesian selection\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.190\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_next_prompts\u001b[0m:\u001b[36m621\u001b[0m - \u001b[31m\u001b[1mError in Bayesian prompt selection: SimpleMetaPromptSpec.vary() got an unexpected keyword argument 'variation_type'\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.190\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_next_prompts\u001b[0m:\u001b[36m623\u001b[0m - \u001b[33m\u001b[1mFalling back to default prompt generation\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:58.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "Make the prompt you write as simple as possible...\u001b[0m\n",
      "\u001b[32m2025-05-12 20:57:59.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "Use plain language in the prompt you write...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a review analysis expert. Read the review provided below and determine its rating on a scale from 1 to 5. \n",
      "\n",
      "Review: {{ review }}\n",
      "Reviewer Name: {{ name }}\n",
      "Location: {{ location }}\n",
      "Date: {{ date }}\n",
      "\n",
      "Provide a clear rating based on the content and tone of the review.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 20:58:01.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m802\u001b[0m - \u001b[1mGenerated 2 new candidates for evaluation.\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:01.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m280\u001b[0m - \u001b[1mRunning for prompt You are a review analysis expert. Read the review provided below and determine its rating on a scale... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:01.324\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4o-mini\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:01.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m280\u001b[0m - \u001b[1mRunning for prompt As a rating assessor, read the review provided and evaluate its sentiment. Based on the content, det... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:01.326\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4o-mini\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a rating assessor, read the review provided and evaluate its sentiment. Based on the content, determine a rating from 1 to 5, where 1 is the lowest and 5 is the highest. Provide your rating along with a brief explanation of your reasoning.\n",
      "\n",
      "Review: {{ review }}\n",
      "Reviewer Name: {{ name }}\n",
      "Location: {{ location }}\n",
      "Date of Review: {{ date }}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 20:58:36.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m813\u001b[0m - \u001b[1mPrompt content: You are a review analysis expert. Read the review provided below and determine its rating on a scale...\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m813\u001b[0m - \u001b[1mPrompt content: As a rating assessor, read the review provided and evaluate its sentiment. Based on the content, det...\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m818\u001b[0m - \u001b[1mUpdating surrogate model with new data\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.321\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m267\u001b[0m - \u001b[32m\u001b[1mExtracted features for 4 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.322\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.322\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.323\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4o-mini\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.323\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4o-mini\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.404\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 31.0000, Correct: 31, Incorrect: 9, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.404\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 30.0000, Correct: 30, Incorrect: 10, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.405\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4o-mini with prompt achieved score: 33.0000, Correct: 33, Incorrect: 7, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.406\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4o-mini with prompt achieved score: 33.0000, Correct: 33, Incorrect: 7, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mFitting GP surrogate model with 4 data points\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.411\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 0/1000, Loss: 5.3103\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.493\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 100/1000, Loss: 5.1000\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.577\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 200/1000, Loss: 5.0490\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.662\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 300/1000, Loss: 5.0262\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.747\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 400/1000, Loss: 5.0143\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.846\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 500/1000, Loss: 5.0073\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:36.955\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 600/1000, Loss: 5.0029\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.081\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 700/1000, Loss: 4.9999\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.170\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 800/1000, Loss: 4.9978\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.260\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 900/1000, Loss: 4.9963\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m318\u001b[0m - \u001b[1mSuccessfully fit Pyro GP model with final loss: 4.9951\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m672\u001b[0m - \u001b[1mSelecting best prompt from 4 prompts using 40 evaluation rows\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m123\u001b[0m - \u001b[1mSelecting best prompt from 4 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.345\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.346\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.346\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4o-mini\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.346\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4o-mini\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.397\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 31.0000, Correct: 31, Incorrect: 9, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.398\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 30.0000, Correct: 30, Incorrect: 10, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.398\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4o-mini with prompt achieved score: 33.0000, Correct: 33, Incorrect: 7, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.399\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4o-mini with prompt achieved score: 33.0000, Correct: 33, Incorrect: 7, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.399\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4o-mini\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.414\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4o-mini with prompt achieved score: 33.0000, Correct: 33, Incorrect: 7, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.415\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m830\u001b[0m - \u001b[32m\u001b[1mIteration 2: Found new best prompt! Score: 33.0000 (Improvement: +2.0000)\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m846\u001b[0m - \u001b[1mPhase 3: Final evaluation on test set...\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m854\u001b[0m - \u001b[1mAdded Pyro dependencies to pyproject.toml (commented)\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mAnalyzing performance by model...\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.417\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:37.417\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:46.673\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:46.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 8.0000, Correct: 8, Incorrect: 2, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:46.674\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:46.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:46.675\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4o-mini\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:46.675\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4o-mini\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.452\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4o-mini with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.453\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4o-mini with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.455\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.466\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 8.0000, Correct: 8, Incorrect: 2, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.467\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m872\u001b[0m - \u001b[32m\u001b[1mBest prompt for model openai/gpt-4.1-nano-2025-04-14 achieved test score: 8.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.468\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4o-mini\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.473\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4o-mini with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.473\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m872\u001b[0m - \u001b[32m\u001b[1mBest prompt for model openai/gpt-4o-mini achieved test score: 7.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.474\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.474\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.482\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 8.0000, Correct: 8, Incorrect: 2, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.483\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.483\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4o-mini\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.483\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4o-mini\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.492\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4o-mini with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.493\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4o-mini with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.493\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.554\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 8.0000, Correct: 8, Incorrect: 2, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.555\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4o-mini\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.562\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4o-mini with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.563\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.571\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 8.0000, Correct: 8, Incorrect: 2, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.572\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m892\u001b[0m - \u001b[32m\u001b[1mTraining complete. Best overall model is openai/gpt-4.1-nano-2025-04-14. Final test score: 8.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m897\u001b[0m - \u001b[1mSaving final best prompt (based on test set).\u001b[0m\n",
      "\u001b[32m2025-05-12 20:58:56.574\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m903\u001b[0m - \u001b[32m\u001b[1mSuccessfully saved best prompt and config.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "await trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b2ad86-80f5-42ab-9379-568a95ae932b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
