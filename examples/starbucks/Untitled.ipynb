{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b745cf72-4faf-4e63-8058-ec4c06e5f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c340dc-e5fa-49b2-9078-190e8f43bbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bill/dev/taskllm/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import csv\n",
    "from enum import Enum\n",
    "\n",
    "from loguru import logger\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from taskllm.optimizer.data import DataSet, Row\n",
    "from taskllm.optimizer.methods import BanditTrainer, BayesianTrainer\n",
    "from taskllm.optimizer.prompt.meta import PromptMode\n",
    "\n",
    "# logger.remove()  # remove the old handler. Else, the old one will work (and continue printing DEBUG logs) along with the new handler added below'\n",
    "# logger.add(sys.stdout, level=\"TRACE\")  # add a new handler which has INFO as the default\n",
    "\n",
    "\n",
    "class Ratings(Enum):\n",
    "    ONE = \"1\"\n",
    "    TWO = \"2\"\n",
    "    THREE = \"3\"\n",
    "    FOUR = \"4\"\n",
    "    FIVE = \"5\"\n",
    "    NA = \"N/A\"\n",
    "\n",
    "\n",
    "class StarbucksReviewRating(BaseModel):\n",
    "    rating: Ratings\n",
    "\n",
    "\n",
    "def sentiment_scoring_function(\n",
    "    row: Row[StarbucksReviewRating], output: StarbucksReviewRating | None\n",
    ") -> float:\n",
    "    if output is None:\n",
    "        return -10\n",
    "    if not row.expected_output:\n",
    "        return 0\n",
    "    logger.trace(f\"Expected: {row.expected_output.rating}, Output: {output.rating}\")\n",
    "    if row.expected_output.rating == output.rating:\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def load_file_as_dataset(path: str) -> DataSet:\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            rating = StarbucksReviewRating(rating=Ratings(row[\"Rating\"]))\n",
    "            rows.append(\n",
    "                Row.create(\n",
    "                    input_dictionary={\n",
    "                        \"review\": row[\"Review\"],\n",
    "                        \"name\": row[\"name\"],\n",
    "                        \"location\": row[\"location\"],\n",
    "                        \"date\": row[\"Date\"],\n",
    "                    },\n",
    "                    output=rating,\n",
    "                )\n",
    "            )\n",
    "    return DataSet(rows=rows[:50], name=\"starbucks_reviews\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aa6f3b0-6885-44a5-aab7-60399f18e058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 20:42:15.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1mUsing CPU for Pyro/Torch computations\u001b[0m\n",
      "\u001b[32m2025-05-12 20:42:15.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m236\u001b[0m - \u001b[1mAll rows: 50\u001b[0m\n",
      "\u001b[32m2025-05-12 20:42:15.960\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m683\u001b[0m - \u001b[34m\u001b[1mBayesianTrainer initialized\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"./starbucks_reviews.csv\"\n",
    "dataset = load_file_as_dataset(csv_path)\n",
    "trainer = BayesianTrainer(\n",
    "    all_rows=dataset,\n",
    "    task_guidance=\"determine the rating of this review\",\n",
    "    keys=[\"review\", \"name\", \"location\", \"date\"],\n",
    "    expected_output_type=StarbucksReviewRating,\n",
    "    scoring_function=sentiment_scoring_function,\n",
    "    num_iterations=2,  # Start with fewer iterations for testing\n",
    "    candidates_per_iteration=2,  # Start with fewer candidates for testing\n",
    "    prompt_mode=PromptMode.SIMPLE,\n",
    "    models=[\n",
    "        \"anthropic/claude-3-haiku-20240307\",\n",
    "        \"openai/gpt-4.1-nano-2025-04-14\",\n",
    "        \"openai/gpt-4.1-mini-2025-04-14\",\n",
    "        \"groq/gemma2-9b-it\",\n",
    "        \"groq/qwen-qwq-32b\"\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197101ec-6e1c-4750-a281-a7772b0e376f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 20:25:44.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m687\u001b[0m - \u001b[1mStarting Bayesian optimization with Pyro: 2 iterations, 2 candidates/iter.\u001b[0m\n",
      "\u001b[32m2025-05-12 20:25:44.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m693\u001b[0m - \u001b[1mPhase 1: Generating and evaluating initial candidates...\u001b[0m\n",
      "\u001b[32m2025-05-12 20:25:44.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m294\u001b[0m - \u001b[1mGenerating prompt content for: determine the rating of this review\n",
      "\n",
      "Use plain language in the prompt you write\u001b[0m\n",
      "\u001b[32m2025-05-12 20:25:44.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m294\u001b[0m - \u001b[1mGenerating prompt content for: determine the rating of this review\n",
      "\n",
      "Make the prompt you write as simple as possible\u001b[0m\n",
      "\u001b[32m2025-05-12 20:25:59.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m715\u001b[0m - \u001b[1mGenerated 2 initial candidate prompts.\u001b[0m\n",
      "\u001b[32m2025-05-12 20:25:59.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m274\u001b[0m - \u001b[1mRunning for prompt 1. Read the provided review carefully to understand the overall sentiment expressed.  \n",
      "2. Identify k... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 20:25:59.608\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 20:25:59.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m274\u001b[0m - \u001b[1mRunning for prompt 1. Read the provided review text carefully.  \n",
      "2. Identify the overall tone of the review. Look for k... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 20:25:59.611\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 20:27:55.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m727\u001b[0m - \u001b[1mFitting initial surrogate model\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:55.659\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m229\u001b[0m - \u001b[32m\u001b[1mExtracted features for 2 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:55.660\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:55.661\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:55.709\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:55.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 19.0000, Correct: 19, Incorrect: 21, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:55.710\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:55.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:55.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m241\u001b[0m - \u001b[1mFitting GP surrogate model with 2 data points\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:56.374\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 0/1000, Loss: 5.9885\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:56.450\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 100/1000, Loss: 3.4325\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:56.525\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 200/1000, Loss: 3.1450\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:56.603\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 300/1000, Loss: 2.9404\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:56.680\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 400/1000, Loss: 2.8643\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:56.759\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 500/1000, Loss: 2.8474\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:56.834\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 600/1000, Loss: 2.8426\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:56.908\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 700/1000, Loss: 2.8406\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:56.979\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 800/1000, Loss: 2.8397\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.078\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 900/1000, Loss: 2.8391\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m280\u001b[0m - \u001b[1mSuccessfully fit Pyro GP model with final loss: 2.8388\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m731\u001b[0m - \u001b[1mPhase 2: Starting 1 optimization iterations...\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m739\u001b[0m - \u001b[1mIteration 2/2\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m634\u001b[0m - \u001b[1mSelecting best prompt from 2 prompts using 40 evaluation rows\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mSelecting best prompt from 2 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.152\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.152\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.186\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 19.0000, Correct: 19, Incorrect: 21, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.187\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.187\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.202\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m750\u001b[0m - \u001b[1mCurrent best score: 34.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_next_prompts\u001b[0m:\u001b[36m446\u001b[0m - \u001b[1mCalculating best score from history\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m611\u001b[0m - \u001b[1mNo rows provided, using 2 prompts for evaluation\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.206\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mpredict_performance\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1mPredicted performance: mean=20.5840, std=3.3240\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.207\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mpredict_performance\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1mPredicted performance: mean=32.4811, std=3.2223\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m628\u001b[0m - \u001b[1mSelected best prompt using surrogate model with predicted score: 32.4811\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.208\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.226\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:27:57.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_next_prompts\u001b[0m:\u001b[36m484\u001b[0m - \u001b[1mGenerating candidate pool for Bayesian selection\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:03.304\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mpredict_performance\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1mPredicted performance: mean=27.0605, std=6.7724\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:03.308\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mpredict_performance\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1mPredicted performance: mean=26.6229, std=6.7946\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:03.311\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mpredict_performance\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1mPredicted performance: mean=26.6844, std=6.7932\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:03.314\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mpredict_performance\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1mPredicted performance: mean=26.7118, std=6.7924\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:03.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_next_prompts\u001b[0m:\u001b[36m577\u001b[0m - \u001b[1mSelected 2 prompts using Bayesian optimization\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:03.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m763\u001b[0m - \u001b[1mGenerated 2 new candidates for evaluation.\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:03.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m274\u001b[0m - \u001b[1mRunning for prompt 1. Read the review carefully.  \n",
      "2. Determine the review's tone: look for words indicating positive, ... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:03.317\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using ModelsEnum.LLAMA_3_8B\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:03.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m274\u001b[0m - \u001b[1mRunning for prompt 1. Carefully analyze the supplied review text.  \n",
      "2. Assess the predominant sentiment of the review b... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:03.318\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using ModelsEnum.LLAMA_3_8B\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 20:28:42.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m774\u001b[0m - \u001b[1mPrompt content: 1. Read the review carefully.  \n",
      "2. Determine the review's tone: look for words indicating positive, ...\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:42.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m774\u001b[0m - \u001b[1mPrompt content: 1. Carefully analyze the supplied review text.  \n",
      "2. Assess the predominant sentiment of the review b...\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:42.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m779\u001b[0m - \u001b[1mUpdating surrogate model with new data\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:42.989\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m229\u001b[0m - \u001b[32m\u001b[1mExtracted features for 4 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:42.990\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:42.991\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:42.992\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using ModelsEnum.LLAMA_3_8B\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:42.992\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using ModelsEnum.LLAMA_3_8B\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.073\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 19.0000, Correct: 19, Incorrect: 21, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.074\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.075\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel ModelsEnum.LLAMA_3_8B with prompt achieved score: 12.0000, Correct: 12, Incorrect: 28, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.075\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel ModelsEnum.LLAMA_3_8B with prompt achieved score: 18.0000, Correct: 18, Incorrect: 22, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m241\u001b[0m - \u001b[1mFitting GP surrogate model with 4 data points\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.080\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 0/1000, Loss: 5.7088\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.166\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 100/1000, Loss: 5.6392\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.243\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 200/1000, Loss: 5.6374\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.320\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 300/1000, Loss: 5.6365\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.424\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 400/1000, Loss: 5.6361\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.509\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 500/1000, Loss: 5.6358\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.596\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 600/1000, Loss: 5.6357\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.671\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 700/1000, Loss: 5.6355\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.745\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 800/1000, Loss: 5.6355\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.818\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m274\u001b[0m - \u001b[34m\u001b[1mSVI iteration 900/1000, Loss: 5.6354\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m280\u001b[0m - \u001b[1mSuccessfully fit Pyro GP model with final loss: 5.6353\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m634\u001b[0m - \u001b[1mSelecting best prompt from 4 prompts using 40 evaluation rows\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mSelecting best prompt from 4 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.890\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.890\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.890\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using ModelsEnum.LLAMA_3_8B\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.891\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using ModelsEnum.LLAMA_3_8B\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.953\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 19.0000, Correct: 19, Incorrect: 21, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.953\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.954\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel ModelsEnum.LLAMA_3_8B with prompt achieved score: 12.0000, Correct: 12, Incorrect: 28, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.954\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel ModelsEnum.LLAMA_3_8B with prompt achieved score: 18.0000, Correct: 18, Incorrect: 22, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.954\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.972\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m797\u001b[0m - \u001b[1mIteration 2: No improvement found. Best score remains 34.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mPhase 3: Final evaluation on test set...\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m815\u001b[0m - \u001b[1mAdded Pyro dependencies to pyproject.toml (commented)\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m822\u001b[0m - \u001b[1mAnalyzing performance by model...\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:43.974\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:53.231\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:53.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 2.0000, Correct: 2, Incorrect: 8, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:28:53.234\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:04.907\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:04.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 6.0000, Correct: 6, Incorrect: 4, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:04.910\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using ModelsEnum.LLAMA_3_8B\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:04.911\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using ModelsEnum.LLAMA_3_8B\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 20:29:13.024\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel ModelsEnum.LLAMA_3_8B with prompt achieved score: 3.0000, Correct: 3, Incorrect: 7, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.026\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel ModelsEnum.LLAMA_3_8B with prompt achieved score: 5.0000, Correct: 5, Incorrect: 5, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.029\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.046\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 2.0000, Correct: 2, Incorrect: 8, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.046\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m833\u001b[0m - \u001b[32m\u001b[1mBest prompt for model anthropic/claude-3-haiku-20240307 achieved test score: 2.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.048\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.053\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 6.0000, Correct: 6, Incorrect: 4, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.054\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m833\u001b[0m - \u001b[32m\u001b[1mBest prompt for model groq/qwen-qwq-32b achieved test score: 6.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.055\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using ModelsEnum.LLAMA_3_8B\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.060\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel ModelsEnum.LLAMA_3_8B with prompt achieved score: 5.0000, Correct: 5, Incorrect: 5, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.060\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m833\u001b[0m - \u001b[32m\u001b[1mBest prompt for model ModelsEnum.LLAMA_3_8B achieved test score: 5.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.061\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.066\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 2.0000, Correct: 2, Incorrect: 8, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.067\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.073\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 6.0000, Correct: 6, Incorrect: 4, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.073\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using ModelsEnum.LLAMA_3_8B\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.074\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using ModelsEnum.LLAMA_3_8B\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.082\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel ModelsEnum.LLAMA_3_8B with prompt achieved score: 3.0000, Correct: 3, Incorrect: 7, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.083\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel ModelsEnum.LLAMA_3_8B with prompt achieved score: 5.0000, Correct: 5, Incorrect: 5, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.083\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.090\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 2.0000, Correct: 2, Incorrect: 8, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.090\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.095\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 6.0000, Correct: 6, Incorrect: 4, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.095\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using ModelsEnum.LLAMA_3_8B\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.101\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel ModelsEnum.LLAMA_3_8B with prompt achieved score: 5.0000, Correct: 5, Incorrect: 5, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.101\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m49\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.106\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 6.0000, Correct: 6, Incorrect: 4, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.107\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m853\u001b[0m - \u001b[32m\u001b[1mTraining complete. Best overall model is groq/qwen-qwq-32b. Final test score: 6.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m858\u001b[0m - \u001b[1mSaving final best prompt (based on test set).\u001b[0m\n",
      "\u001b[32m2025-05-12 20:29:13.107\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m864\u001b[0m - \u001b[32m\u001b[1mSuccessfully saved best prompt and config.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "await trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b2ad86-80f5-42ab-9379-568a95ae932b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
