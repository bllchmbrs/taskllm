{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b745cf72-4faf-4e63-8058-ec4c06e5f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c340dc-e5fa-49b2-9078-190e8f43bbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bill/dev/taskllm/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from enum import Enum\n",
    "\n",
    "from loguru import logger\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from taskllm.optimizer.data import DataSet, Row\n",
    "from taskllm.optimizer.methods import BayesianTrainer\n",
    "from taskllm.optimizer.prompt.meta import PromptMode\n",
    "\n",
    "# logger.remove()  # remove the old handler. Else, the old one will work (and continue printing DEBUG logs) along with the new handler added below'\n",
    "# logger.add(sys.stdout, level=\"TRACE\")  # add a new handler which has INFO as the default\n",
    "\n",
    "\n",
    "class Ratings(Enum):\n",
    "    ONE = \"1\"\n",
    "    TWO = \"2\"\n",
    "    THREE = \"3\"\n",
    "    FOUR = \"4\"\n",
    "    FIVE = \"5\"\n",
    "    NA = \"N/A\"\n",
    "\n",
    "\n",
    "class StarbucksReviewRating(BaseModel):\n",
    "    rating: Ratings\n",
    "\n",
    "\n",
    "def sentiment_scoring_function(\n",
    "    row: Row[StarbucksReviewRating], output: StarbucksReviewRating | None\n",
    ") -> float:\n",
    "    if output is None:\n",
    "        return -10\n",
    "    if not row.expected_output:\n",
    "        return 0\n",
    "    logger.trace(f\"Expected: {row.expected_output.rating}, Output: {output.rating}\")\n",
    "    if row.expected_output.rating == output.rating:\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def load_file_as_dataset(path: str) -> DataSet:\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            rating = StarbucksReviewRating(rating=Ratings(row[\"Rating\"]))\n",
    "            rows.append(\n",
    "                Row.create(\n",
    "                    input_dictionary={\n",
    "                        \"review\": row[\"Review\"],\n",
    "                        \"name\": row[\"name\"],\n",
    "                        \"location\": row[\"location\"],\n",
    "                        \"date\": row[\"Date\"],\n",
    "                    },\n",
    "                    output=rating,\n",
    "                )\n",
    "            )\n",
    "    return DataSet(rows=rows[:50], name=\"starbucks_reviews\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aa6f3b0-6885-44a5-aab7-60399f18e058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:36:41.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m208\u001b[0m - \u001b[1mUsing CPU for Pyro/Torch computations\u001b[0m\n",
      "\u001b[32m2025-05-12 21:36:41.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m263\u001b[0m - \u001b[1mAll rows: 50\u001b[0m\n",
      "\u001b[32m2025-05-12 21:36:41.895\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m727\u001b[0m - \u001b[34m\u001b[1mBayesianTrainer initialized\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"./starbucks_reviews.csv\"\n",
    "dataset = load_file_as_dataset(csv_path)\n",
    "trainer = BayesianTrainer(\n",
    "    all_rows=dataset,\n",
    "    task_guidance=\"determine the rating of this review\",\n",
    "    keys=[\"review\", \"name\", \"location\", \"date\"],\n",
    "    expected_output_type=StarbucksReviewRating,\n",
    "    scoring_function=sentiment_scoring_function,\n",
    "    num_iterations=4,  # Start with fewer iterations for testing\n",
    "    candidates_per_iteration=4,  # Start with fewer candidates for testing\n",
    "    prompt_mode=PromptMode.SIMPLE,\n",
    "    models=[\n",
    "        \"anthropic/claude-3-haiku-20240307\",\n",
    "        \"openai/gpt-4.1-nano-2025-04-14\",\n",
    "        \"openai/gpt-4.1-mini-2025-04-14\",\n",
    "        \"groq/gemma2-9b-it\",\n",
    "        \"groq/qwen-qwq-32b\"\n",
    "    ],\n",
    "    failure_analysis_enabled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "197101ec-6e1c-4750-a281-a7772b0e376f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:36:43.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mStarting Bayesian optimization with Pyro: 4 iterations, 4 candidates/iter.\u001b[0m\n",
      "\u001b[32m2025-05-12 21:36:43.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mPhase 1: Generating and evaluating initial candidates...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:36:43.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "Use plain language in the prompt you write...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:36:45.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "Make the prompt you write as simple as possible...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a review analysis expert, your role is to determine the overall rating of a customer review. Carefully read the review provided and assess the sentiments expressed. Consider the key points mentioned by the reviewer to decide how positive or negative the review is. Based on your assessment, assign a rating from 1 to 5, where 1 is very negative and 5 is very positive. Here's the specific context for your analysis:\n",
      "\n",
      "- Review: {{ review }}\n",
      "- Name of reviewer: {{ name }}\n",
      "- Location of reviewer: {{ location }}\n",
      "- Date of review: {{ date }}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:36:47.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "Make the prompt you write as simple as possible...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a review analyst. Determine the rating for the following review based on its sentiment. Consider the tone, keywords, and overall context to assign a rating from 1 to 5. Review details:\n",
      "\n",
      "Review: {{ review }}\n",
      "Reviewer Name: {{ name }}\n",
      "Location: {{ location }}\n",
      "Date: {{ date }}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:36:48.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "Use plain language in the prompt you write...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a review evaluator, analyze the provided review from {{ name }} located in {{ location }} dated {{ date }}. Determine the appropriate rating based on the content of the review.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:36:49.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mGenerated 4 initial candidate prompts.\u001b[0m\n",
      "\u001b[32m2025-05-12 21:36:49.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mRunning for prompt As a review analysis expert, your role is to determine the overall rating of a customer review. Care... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:36:49.919\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:36:49.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mRunning for prompt You are a review analyst. Determine the rating for the following review based on its sentiment. Cons... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:36:49.921\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:36:49.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mRunning for prompt As a review evaluator, analyze the provided review from {{ name }} located in {{ location }} dated {... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:36:49.923\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:36:49.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mRunning for prompt As a reviewer analyzer, read the review provided below and determine its overall rating based on the... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:36:49.924\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a reviewer analyzer, read the review provided below and determine its overall rating based on the sentiment and specific feedback mentioned. Pay attention to the content of the review, the name of the reviewer {{ name }}, their location {{ location }}, and the date of the review {{ date }}. Provide a rating from 1 to 5, where 1 indicates a very negative review and 5 indicates a very positive review.\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:40:10.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecording failures\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:10.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecording failures\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:10.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecording failures\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:10.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecording failures\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:10.956\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:10.988\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:10.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 33, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:10.989\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.004\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.005\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.017\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 3.0000, Correct: 3, Incorrect: 37, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.019\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.030\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 0.0000, Correct: 0, Incorrect: 40, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m22\u001b[0m - \u001b[1mFitting initial surrogate model\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.032\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m267\u001b[0m - \u001b[32m\u001b[1mExtracted features for 4 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.032\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.032\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.033\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.033\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.097\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 33, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.098\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.098\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 3.0000, Correct: 3, Incorrect: 37, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.099\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 0.0000, Correct: 0, Incorrect: 40, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mFitting GP surrogate model with 4 data points\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.104\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 0/1000, Loss: 14.8866\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.182\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 100/1000, Loss: 7.7292\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.258\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 200/1000, Loss: 6.7373\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.333\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 300/1000, Loss: 6.0869\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.408\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 400/1000, Loss: 5.7840\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.483\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 500/1000, Loss: 5.7097\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.558\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 600/1000, Loss: 5.6906\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.633\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 700/1000, Loss: 5.6838\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.699\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 800/1000, Loss: 5.6807\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.765\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 900/1000, Loss: 5.6791\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m318\u001b[0m - \u001b[1mSuccessfully fit Pyro GP model with final loss: 5.6781\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mPhase 2: Starting 3 optimization iterations...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mIteration 2/4\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m672\u001b[0m - \u001b[1mSelecting best prompt from 4 prompts using 40 evaluation rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m142\u001b[0m - \u001b[1mSelecting best prompt from 4 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.833\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.833\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.833\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.834\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.881\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 33, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.882\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.882\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 3.0000, Correct: 3, Incorrect: 37, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.882\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 0.0000, Correct: 0, Incorrect: 40, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.883\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.897\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mCurrent best score: 34.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mPerforming failure analysis\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_consistent_failures\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mFound 37 failures and 2 will be used\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mFound 2 consistently failing examples\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:11.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "The prompt should specifically handle these challenging cases:\n",
      "...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:14.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "The prompt should specifically handle these challenging cases:\n",
      "...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert sentiment analysis system tasked with determining the appropriate rating for customer reviews based on their content. Review the submitted review for its emotional tone, context, and specific complaints. Consider the overall sentiment as well as any explicit dissatisfaction expressed by the reviewer, especially when it concerns service or product integrity. Given the review: '{{ review }}', written by '{{ name }}' from '{{ location }}' on '{{ date }}', evaluate the review and assign a rating accordingly. Note that severe complaints or expressions of disappointment should be treated with higher severity, potentially resulting in lower ratings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:40:17.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "The prompt should specifically handle these challenging cases:\n",
      "...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a sentiment analysis expert, your task is to evaluate the tone and context of the given review and determine a rating based on the provided criteria. Please read the review carefully and assess the overall sentiment, focusing specifically on negativity or dissatisfaction levels. Use the following review details:\n",
      "- Review: {{ review }}\n",
      "- Reviewer Name: {{ name }}\n",
      "- Location: {{ location }}\n",
      "- Date of Review: {{ date }}\n",
      "\n",
      "Based on the sentiment conveyed in the review, assign a rating from the following options:\n",
      "- Ratings.ONE: '1'\n",
      "- Ratings.TWO: '2'\n",
      "- Ratings.THREE: '3'\n",
      "- Ratings.FOUR: '4'\n",
      "- Ratings.FIVE: '5'\n",
      "\n",
      "Be sure to consider past experiences and sentiments shared within the review to accurately reflect the reviewer's feelings in your assigned rating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:40:20.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "The prompt should specifically handle these challenging cases:\n",
      "...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert sentiment analyzer. Your task is to determine the rating of a customer review based on its content. Please closely read the review provided, paying special attention to any expressions of dissatisfaction or negative sentiment. Assign a rating based on the following scale: 1 (very dissatisfied) to 5 (very satisfied). Use the review, customer’s name, location, and the date of the review as context to inform your analysis. Here is the review data: Review: '{{ review }}', Name: '{{ name }}', Location: '{{ location }}', Date: '{{ date }}'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:40:23.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mGenerated 4 new candidates for evaluation.\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:23.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mRunning for prompt You are an expert sentiment analysis system tasked with determining the appropriate rating for custo... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:23.385\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:23.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mRunning for prompt As a sentiment analysis expert, your task is to evaluate the tone and context of the given review an... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:23.388\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:23.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mRunning for prompt You are an expert sentiment analyzer. Your task is to determine the rating of a customer review base... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:23.391\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:23.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mRunning for prompt You are a sentiment analysis expert tasked with determining the appropriate rating for customer revi... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:40:23.393\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a sentiment analysis expert tasked with determining the appropriate rating for customer reviews of Starbucks based on the provided text of the review. Analyze the review content to identify the overall sentiment expressed, taking particular care to consider aggressive language or strong dissatisfaction that indicates a low rating. Consider the review provided by {{ name }} from {{ location }} on {{ date }}: '{{ review }}'. Based on your analysis, classify the sentiment into a rating from one (1) to five (5), with one being the most negative and five being the most positive. Return the determined rating in the specified format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:42:44.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecording failures\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecording failures\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecording failures\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecording failures\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.155\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.179\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mPrompt content: You are an expert sentiment analysis system tasked with determining the appropriate rating for custo...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.180\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.198\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 29.0000, Correct: 29, Incorrect: 11, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mPrompt content: As a sentiment analysis expert, your task is to evaluate the tone and context of the given review an...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.200\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.213\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mPrompt content: You are an expert sentiment analyzer. Your task is to determine the rating of a customer review base...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.214\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.226\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 32.0000, Correct: 32, Incorrect: 8, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mPrompt content: You are a sentiment analysis expert tasked with determining the appropriate rating for customer revi...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mUpdating surrogate model with new data\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.228\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m267\u001b[0m - \u001b[32m\u001b[1mExtracted features for 8 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.228\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.229\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.229\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.229\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.230\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.230\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.230\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.230\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.316\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 33, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.317\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.317\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 3.0000, Correct: 3, Incorrect: 37, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.318\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 0.0000, Correct: 0, Incorrect: 40, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.318\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.318\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 29.0000, Correct: 29, Incorrect: 11, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.319\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.319\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 32.0000, Correct: 32, Incorrect: 8, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mFitting GP surrogate model with 8 data points\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.324\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 0/1000, Loss: 11.4470\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.396\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 100/1000, Loss: 11.3531\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.467\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 200/1000, Loss: 11.3519\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.537\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 300/1000, Loss: 11.3517\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.602\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 400/1000, Loss: 11.3516\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.667\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 500/1000, Loss: 11.3516\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.730\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 600/1000, Loss: 11.3516\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.793\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 700/1000, Loss: 11.3515\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.854\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 800/1000, Loss: 11.3515\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.915\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 900/1000, Loss: 11.3515\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m318\u001b[0m - \u001b[1mSuccessfully fit Pyro GP model with final loss: 11.3515\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m672\u001b[0m - \u001b[1mSelecting best prompt from 8 prompts using 40 evaluation rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m142\u001b[0m - \u001b[1mSelecting best prompt from 8 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.975\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.976\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.976\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.976\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.977\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.977\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.977\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:44.977\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.064\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 33, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.065\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.065\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 3.0000, Correct: 3, Incorrect: 37, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.066\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 0.0000, Correct: 0, Incorrect: 40, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.066\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.066\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 29.0000, Correct: 29, Incorrect: 11, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.067\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.067\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 32.0000, Correct: 32, Incorrect: 8, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.067\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.081\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mIteration 2: No improvement found. Best score remains 34.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mIteration 3/4\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m672\u001b[0m - \u001b[1mSelecting best prompt from 8 prompts using 40 evaluation rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m142\u001b[0m - \u001b[1mSelecting best prompt from 8 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.083\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.083\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.083\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.083\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.084\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.084\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.084\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.084\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.171\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 33, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.171\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.172\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 3.0000, Correct: 3, Incorrect: 37, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.172\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 0.0000, Correct: 0, Incorrect: 40, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.172\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.173\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 29.0000, Correct: 29, Incorrect: 11, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.173\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.173\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 32.0000, Correct: 32, Incorrect: 8, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.174\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.188\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mPerforming failure analysis\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_consistent_failures\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mFound 37 failures and 2 will be used\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mFound 2 consistently failing examples\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:45.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "The prompt should specifically handle these challenging cases:\n",
      "...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:52.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "The prompt should specifically handle these challenging cases:\n",
      "...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an advanced sentiment analysis model tasked with determining the rating of a customer review. Your output must represent the overall satisfaction level of the reviewer based on the content of the review. The review may encompass various aspects of the customer experience, including service quality, product satisfaction, and specific incidents that highlight positive or negative feelings. \n",
      "\n",
      "Follow these steps to deliver your output:\n",
      "1. Analyze the provided review text for emotional cues, customer satisfaction levels, and the context of their experience.\n",
      "2. Classify the review into a rating system where:\n",
      "   - Ratings.ONE corresponds to very negative sentiment\n",
      "   - Ratings.TWO corresponds to negative sentiment\n",
      "   - Ratings.THREE corresponds to neutral sentiment\n",
      "   - Ratings.FOUR corresponds to positive sentiment\n",
      "   - Ratings.FIVE corresponds to very positive sentiment\n",
      "3. Pay special attention to key phrases that indicate dissatisfaction or frustration, especially in cases where disputes with staff or service delays are mentioned.\n",
      "\n",
      "Process the following contextual information: \n",
      "- Review Text: {{ review }}\n",
      "- Reviewer Name: {{ name }}\n",
      "- Reviewer Location: {{ location }}\n",
      "- Review Date: {{ date }}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:42:54.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "The prompt should specifically handle these challenging cases:\n",
      "...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a sentiment analysis model tasked with determining the rating for customer reviews of Starbucks. Analyze the following review to assign an appropriate rating based on the expressed sentiments. Specifically, identify the tone, severity of the complaints, and overall satisfaction reflected in the text. Consider technical indicators like negative phrases, customer frustration, and instances of unprofessional service to guide your evaluation. Review Input: {{ review }}. Customer Name: {{ name }}. Location: {{ location }}. Review Date: {{ date }}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:42:57.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "The prompt should specifically handle these challenging cases:\n",
      "...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a critical sentiment analysis engine tasked with determining the customer rating from a detailed review. Analyze the review content for emotional tone and customer satisfaction levels. Consider negative experiences that suggest frustration, disappointment, or poor service, particularly focusing on how the reviewer's complaints about service and management reflect their overall dissatisfaction. \n",
      "\n",
      "For the provided context, process the following input: \n",
      "- Review: {{ review }} \n",
      "- Customer Name: {{ name }} \n",
      "- Location: {{ location }} \n",
      "- Date of Review: {{ date }} \n",
      "\n",
      "Your output should categorize the sentiment into ratings, specifically returning a rating of '1' if the review conveys a significant negative experience. Be attentive to details highlighting dissatisfaction and poor service, and assign a rating based on the severity of the issues expressed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:42:59.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mGenerated 4 new candidates for evaluation.\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:59.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mRunning for prompt You are an advanced sentiment analysis model tasked with determining the rating of a customer review... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:59.456\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:59.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mRunning for prompt You are a sentiment analysis model tasked with determining the rating for customer reviews of Starbu... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:59.459\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:59.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mRunning for prompt You are a critical sentiment analysis engine tasked with determining the customer rating from a deta... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:59.463\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:59.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mRunning for prompt You are a review rating expert. Analyze the following customer review and determine its appropriate ... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:42:59.465\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a review rating expert. Analyze the following customer review and determine its appropriate rating based on sentiment and overall customer experience. Pay special attention to negative experiences related to customer service and unresolved issues. Use the context provided to enhance your analysis. \n",
      "\n",
      "Review: {{ review }}\n",
      "Customer Name: {{ name }}\n",
      "Location: {{ location }}\n",
      "Date of Review: {{ date }}\n",
      "\n",
      "Ensure to give a rating of 1 to 5, where 1 indicates a very poor experience and 5 indicates an excellent experience.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:45:05.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecording failures\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecording failures\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecording failures\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecording failures\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.013\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.039\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 25.0000, Correct: 25, Incorrect: 15, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mPrompt content: You are an advanced sentiment analysis model tasked with determining the rating of a customer review...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.041\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.057\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 8.0000, Correct: 8, Incorrect: 32, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mPrompt content: You are a sentiment analysis model tasked with determining the rating for customer reviews of Starbu...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.058\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.073\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 35.0000, Correct: 35, Incorrect: 5, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mPrompt content: You are a critical sentiment analysis engine tasked with determining the customer rating from a deta...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.074\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.086\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 35.0000, Correct: 35, Incorrect: 5, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mPrompt content: You are a review rating expert. Analyze the following customer review and determine its appropriate ...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mUpdating surrogate model with new data\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.087\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m267\u001b[0m - \u001b[32m\u001b[1mExtracted features for 12 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.088\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.088\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.088\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.089\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.089\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.090\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.090\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.090\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.090\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.091\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.091\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.091\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.235\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 33, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.237\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.238\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 3.0000, Correct: 3, Incorrect: 37, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.240\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 0.0000, Correct: 0, Incorrect: 40, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.241\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.243\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 29.0000, Correct: 29, Incorrect: 11, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.245\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.247\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 32.0000, Correct: 32, Incorrect: 8, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.251\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 25.0000, Correct: 25, Incorrect: 15, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.254\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 8.0000, Correct: 8, Incorrect: 32, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.255\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 35.0000, Correct: 35, Incorrect: 5, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.256\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 35.0000, Correct: 35, Incorrect: 5, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mFitting GP surrogate model with 12 data points\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.265\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 0/1000, Loss: 17.0228\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.345\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 100/1000, Loss: 16.8673\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.431\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 200/1000, Loss: 16.8576\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.499\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 300/1000, Loss: 16.8539\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.564\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 400/1000, Loss: 16.8521\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.630\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 500/1000, Loss: 16.8510\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.696\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 600/1000, Loss: 16.8503\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.761\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 700/1000, Loss: 16.8498\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.823\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 800/1000, Loss: 16.8494\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.887\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 900/1000, Loss: 16.8492\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m318\u001b[0m - \u001b[1mSuccessfully fit Pyro GP model with final loss: 16.8490\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m672\u001b[0m - \u001b[1mSelecting best prompt from 12 prompts using 40 evaluation rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m142\u001b[0m - \u001b[1mSelecting best prompt from 12 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.949\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.950\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.950\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.950\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.950\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.951\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.951\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.951\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.951\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.951\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.952\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:05.952\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.087\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 33, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.088\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.088\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 3.0000, Correct: 3, Incorrect: 37, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.088\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 0.0000, Correct: 0, Incorrect: 40, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.089\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.089\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 29.0000, Correct: 29, Incorrect: 11, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.089\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.090\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 32.0000, Correct: 32, Incorrect: 8, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.090\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 25.0000, Correct: 25, Incorrect: 15, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.091\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 8.0000, Correct: 8, Incorrect: 32, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.091\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 35.0000, Correct: 35, Incorrect: 5, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.091\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 35.0000, Correct: 35, Incorrect: 5, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.092\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.108\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 35.0000, Correct: 35, Incorrect: 5, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.108\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m63\u001b[0m - \u001b[32m\u001b[1mIteration 3: Found new best prompt! Score: 35.0000 (Improvement: +1.0000)\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mIteration 4/4\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m672\u001b[0m - \u001b[1mSelecting best prompt from 12 prompts using 40 evaluation rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m142\u001b[0m - \u001b[1mSelecting best prompt from 12 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.109\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.109\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.110\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.110\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.110\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.110\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.111\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.111\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.111\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.111\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.112\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.112\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.253\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 33, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.253\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.254\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 3.0000, Correct: 3, Incorrect: 37, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.255\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 0.0000, Correct: 0, Incorrect: 40, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.255\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.255\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 29.0000, Correct: 29, Incorrect: 11, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.256\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.256\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 32.0000, Correct: 32, Incorrect: 8, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.257\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 25.0000, Correct: 25, Incorrect: 15, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.257\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 8.0000, Correct: 8, Incorrect: 32, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.257\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 35.0000, Correct: 35, Incorrect: 5, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.258\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 35.0000, Correct: 35, Incorrect: 5, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.258\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.279\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 35.0000, Correct: 35, Incorrect: 5, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mPerforming failure analysis\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_consistent_failures\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mFound 39 failures and 2 will be used\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mFound 2 consistently failing examples\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:06.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "The prompt should specifically handle these challenging cases:\n",
      "...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:10.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "The prompt should specifically handle these challenging cases:\n",
      "...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a sentiment analysis expert. Your task is to determine the appropriate rating for customer reviews of Starbucks based on the content provided. Analyze the review text carefully and consider the customer's sentiments and experiences they describe. \n",
      "\n",
      "Instructions:\n",
      "1. Read the review text provided. \n",
      "2. Identify the overall sentiment expressed in the review. Consider both positive and negative statements and weigh them accordingly.\n",
      "3. Use the following rating scale: \n",
      "   - FIVE (5): for reviews that express strong satisfaction and positive sentiments.\n",
      "   - FOUR (4): for reviews that express general satisfaction but may have minor complaints.\n",
      "   - THREE (3): for neutral reviews with mixed sentiments.\n",
      "   - TWO (2): for reviews that express dissatisfaction but have some redeeming qualities.\n",
      "   - ONE (1): for reviews that express strong dissatisfaction and negative sentiments without any redeeming qualities.\n",
      "4. Assign the appropriate rating based on your analysis of the review. \n",
      "\n",
      "Review details:\n",
      "- Review: {{ review }}\n",
      "- Name: {{ name }}\n",
      "- Location: {{ location }}\n",
      "- Date: {{ date }}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:45:13.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "The prompt should specifically handle these challenging cases:\n",
      "...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert sentiment analysis model. Your task is to evaluate and determine the rating of the customer review provided. Carefully analyze the content for indicators of customer satisfaction or dissatisfaction, and pay special attention to nuanced phrases and overall sentiment context. Use the following inputs to inform your analysis: review text is {{ review }}, name of the reviewer is {{ name }}, location is {{ location }}, and the review date is {{ date }}. Assign a rating between 1 to 5 stars, where 5 represents extreme satisfaction and 1 represents extreme dissatisfaction. Be sure to use the specific phrases indicative of each rating level for accuracy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:45:17.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.prompt.meta\u001b[0m:\u001b[36mgenerate_spec\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mGenerating simple prompt content for: determine the rating of this review\n",
      "\n",
      "The prompt should specifically handle these challenging cases:\n",
      "...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a rating evaluator, analyze the following customer review and assign a rating based on the content provided. Consider the overall sentiment of the review, any specific mentions of service quality, product satisfaction, and any complaints or praise. Use the information from the customer’s name, location, and review date to inform your decision but focus primarily on the review's sentiment to determine the appropriate rating. \n",
      "\n",
      "Review details:\n",
      "- Review: {{ review }}\n",
      "- Customer Name: {{ name }}\n",
      "- Location: {{ location }}\n",
      "- Date of Review: {{ date }}\n",
      "\n",
      "Respond with a rating that fits the content of the review, where possible ratings range from 1 to 5, with 1 being very negative and 5 being very positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:45:19.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mGenerated 4 new candidates for evaluation.\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:19.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mRunning for prompt You are a sentiment analysis expert. Your task is to determine the appropriate rating for customer r... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:19.858\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:19.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mRunning for prompt You are an expert sentiment analysis model. Your task is to evaluate and determine the rating of the... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:19.861\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:19.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mRunning for prompt As a rating evaluator, analyze the following customer review and assign a rating based on the conten... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:19.863\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/gemma2-9b-it\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:19.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mRunning for prompt You are a ratings evaluator skilled in analyzing customer reviews. Your task is to determine the ove... against 40 rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:45:19.865\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a ratings evaluator skilled in analyzing customer reviews. Your task is to determine the overall rating for the review provided. Carefully read the text and assess the sentiments expressed within it. Use the following scale to assign a rating: 1 star for very negative feedback, 2 stars for negative but somewhat constructive feedback, 3 stars for neutral reviews, 4 stars for positive feedback, and 5 stars for overwhelmingly positive reviews. \n",
      "\n",
      "Here is the review to evaluate: {{ review }}. The review was written by {{ name }} from {{ location }} on {{ date }}. After analyzing the review, provide the appropriate rating based on the sentiments expressed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:25.073\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30258, Requested 253. Please try again in 1.022999999s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:25.286\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30151, Requested 354. Please try again in 1.010999999s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:25.536\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30031, Requested 272. Please try again in 607ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:25.773\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29915, Requested 419. Please try again in 668ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:26.000\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 29798, Requested 233. Please try again in 61ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:26.613\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30733, Requested 326. Please try again in 2.118s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:26.821\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30634, Requested 369. Please try again in 2.007s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:27.064\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30514, Requested 250. Please try again in 1.529s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:27.277\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30404, Requested 265. Please try again in 1.338s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:27.487\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30301, Requested 335. Please try again in 1.273s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:27.690\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30198, Requested 359. Please try again in 1.115s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:27.940\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30074, Requested 274. Please try again in 696ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:48.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecording failures\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:48.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecording failures\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:48.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecording failures\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:48.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mrun_for_prompt\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecording failures\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:48.230\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:48.254\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:48.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 10.0000, Correct: 10, Incorrect: 30, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:48.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mPrompt content: You are a sentiment analysis expert. Your task is to determine the appropriate rating for customer r...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:48.256\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:48.270\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:48.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 30.0000, Correct: 30, Incorrect: 10, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:48.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mPrompt content: You are an expert sentiment analysis model. Your task is to evaluate and determine the rating of the...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:48.272\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/gemma2-9b-it\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.218\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30631, Requested 359. Please try again in 1.98s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:52.570\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30452, Requested 274. Please try again in 1.452s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.571\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/gemma2-9b-it with prompt achieved score: 12.0000, Correct: 32, Incorrect: 8, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mPrompt content: As a rating evaluator, analyze the following customer review and assign a rating based on the conten...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.577\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.596\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 33.0000, Correct: 33, Incorrect: 7, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mPrompt content: You are a ratings evaluator skilled in analyzing customer reviews. Your task is to determine the ove...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mUpdating surrogate model with new data\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.599\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m267\u001b[0m - \u001b[32m\u001b[1mExtracted features for 16 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.599\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.599\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.600\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.600\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.600\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.601\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.601\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.601\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.601\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.601\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.602\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.602\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.602\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.602\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.603\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/gemma2-9b-it\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:52.603\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:52.958\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30254, Requested 359. Please try again in 1.226s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:53.162\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30166, Requested 274. Please try again in 880ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.184\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 33, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.185\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.185\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 3.0000, Correct: 3, Incorrect: 37, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.185\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 0.0000, Correct: 0, Incorrect: 40, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.186\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.186\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 29.0000, Correct: 29, Incorrect: 11, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.187\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.187\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 32.0000, Correct: 32, Incorrect: 8, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.188\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 25.0000, Correct: 25, Incorrect: 15, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.188\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 8.0000, Correct: 8, Incorrect: 32, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.189\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 35.0000, Correct: 35, Incorrect: 5, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.189\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 35.0000, Correct: 35, Incorrect: 5, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.190\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 10.0000, Correct: 10, Incorrect: 30, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.190\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 30.0000, Correct: 30, Incorrect: 10, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.191\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/gemma2-9b-it with prompt achieved score: 12.0000, Correct: 32, Incorrect: 8, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.191\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 33.0000, Correct: 33, Incorrect: 7, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mFitting GP surrogate model with 16 data points\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.199\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 0/1000, Loss: 22.4019\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:53.283\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 100/1000, Loss: 22.3861\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.350\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 200/1000, Loss: 22.3857\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.416\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 300/1000, Loss: 22.3855\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.480\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 400/1000, Loss: 22.3854\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.543\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 500/1000, Loss: 22.3853\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.605\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 600/1000, Loss: 22.3853\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.667\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 700/1000, Loss: 22.3852\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.729\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 800/1000, Loss: 22.3852\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.790\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m312\u001b[0m - \u001b[34m\u001b[1mSVI iteration 900/1000, Loss: 22.3852\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mfit_surrogate_model\u001b[0m:\u001b[36m318\u001b[0m - \u001b[1mSuccessfully fit Pyro GP model with final loss: 22.3852\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m672\u001b[0m - \u001b[1mSelecting best prompt from 16 prompts using 40 evaluation rows\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mselect_best_prompt\u001b[0m:\u001b[36m142\u001b[0m - \u001b[1mSelecting best prompt from 16 prompts\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.851\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.851\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.851\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.852\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.852\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.852\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.852\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.853\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.853\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.853\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.853\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.854\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.854\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.961\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.961\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using groq/gemma2-9b-it\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:53.961\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.687\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_output\u001b[0m:\u001b[36m69\u001b[0m - \u001b[31m\u001b[1mError executing prompt: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jt6t4sn9em7s4mzybzfdxjzh` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 30726, Requested 274. Please try again in 2.001s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.717\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 33, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.718\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.718\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 3.0000, Correct: 3, Incorrect: 37, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.719\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 0.0000, Correct: 0, Incorrect: 40, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.720\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.720\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 29.0000, Correct: 29, Incorrect: 11, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.721\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 34.0000, Correct: 34, Incorrect: 6, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.722\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 32.0000, Correct: 32, Incorrect: 8, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.722\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 25.0000, Correct: 25, Incorrect: 15, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.723\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 8.0000, Correct: 8, Incorrect: 32, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.724\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 35.0000, Correct: 35, Incorrect: 5, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.725\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 35.0000, Correct: 35, Incorrect: 5, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.725\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 10.0000, Correct: 10, Incorrect: 30, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.726\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 30.0000, Correct: 30, Incorrect: 10, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.726\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/gemma2-9b-it with prompt achieved score: 22.0000, Correct: 32, Incorrect: 8, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.727\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 33.0000, Correct: 33, Incorrect: 7, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.727\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 40 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:46:54.747\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 40 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 35.0000, Correct: 35, Incorrect: 5, Unlabelled: 0 out of 40\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mIteration 4: No improvement found. Best score remains 35.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mPhase 3: Final evaluation on test set...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mAdded Pyro dependencies to pyproject.toml (commented)\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mAnalyzing performance by model...\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.749\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.749\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.749\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:46:54.749\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:47:32.162\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:47:32.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 3.0000, Correct: 3, Incorrect: 7, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:47:32.165\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:47:32.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 0.0000, Correct: 0, Incorrect: 10, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:47:32.167\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:47:32.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 2.0000, Correct: 2, Incorrect: 8, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:47:32.169\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:47:32.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 2.0000, Correct: 2, Incorrect: 8, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:47:32.170\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:47:32.171\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:47:32.172\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:47:32.172\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:47:32.172\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-12 21:48:43.863\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:48:43.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 8.0000, Correct: 8, Incorrect: 2, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:48:43.866\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:48:43.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 0.0000, Correct: 0, Incorrect: 10, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:48:43.867\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:48:43.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 9.0000, Correct: 9, Incorrect: 1, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:48:43.869\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:48:43.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 9.0000, Correct: 9, Incorrect: 1, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:48:43.871\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:48:43.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 9.0000, Correct: 9, Incorrect: 1, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:48:43.873\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:48:43.873\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:48:43.874\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:48:43.875\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:12.989\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:12.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:12.991\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:12.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:12.993\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:12.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:12.995\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:12.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:13.000\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:13.000\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:23.975\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:23.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 9.0000, Correct: 9, Incorrect: 1, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:23.977\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:23.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:23.980\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/gemma2-9b-it\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:26.968\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:26.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/gemma2-9b-it with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:26.971\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:26.988\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:26.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 3.0000, Correct: 3, Incorrect: 7, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:26.989\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m84\u001b[0m - \u001b[32m\u001b[1mBest prompt for model anthropic/claude-3-haiku-20240307 achieved test score: 3.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:26.990\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:26.997\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:26.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 9.0000, Correct: 9, Incorrect: 1, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:26.998\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m84\u001b[0m - \u001b[32m\u001b[1mBest prompt for model groq/qwen-qwq-32b achieved test score: 9.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:26.999\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.005\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.006\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m84\u001b[0m - \u001b[32m\u001b[1mBest prompt for model openai/gpt-4.1-mini-2025-04-14 achieved test score: 7.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.006\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.013\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 9.0000, Correct: 9, Incorrect: 1, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.014\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m84\u001b[0m - \u001b[32m\u001b[1mBest prompt for model openai/gpt-4.1-nano-2025-04-14 achieved test score: 9.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.015\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/gemma2-9b-it\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.020\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/gemma2-9b-it with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.021\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m84\u001b[0m - \u001b[32m\u001b[1mBest prompt for model groq/gemma2-9b-it achieved test score: 7.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.022\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.022\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.022\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.022\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.036\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 3.0000, Correct: 3, Incorrect: 7, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.037\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 0.0000, Correct: 0, Incorrect: 10, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.037\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 2.0000, Correct: 2, Incorrect: 8, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.038\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 2.0000, Correct: 2, Incorrect: 8, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.038\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.038\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.039\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.039\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.039\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.059\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 8.0000, Correct: 8, Incorrect: 2, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.059\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 0.0000, Correct: 0, Incorrect: 10, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.060\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 9.0000, Correct: 9, Incorrect: 1, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.060\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 9.0000, Correct: 9, Incorrect: 1, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.060\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 9.0000, Correct: 9, Incorrect: 1, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.061\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.061\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.061\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.061\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.076\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.077\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.077\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.078\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.078\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.079\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.087\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 9.0000, Correct: 9, Incorrect: 1, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.088\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.088\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/gemma2-9b-it\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.092\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/gemma2-9b-it with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.093\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using anthropic/claude-3-haiku-20240307\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.119\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel anthropic/claude-3-haiku-20240307 with prompt achieved score: 3.0000, Correct: 3, Incorrect: 7, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.119\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.124\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 9.0000, Correct: 9, Incorrect: 1, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.124\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-mini-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.132\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-mini-2025-04-14 with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.133\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using openai/gpt-4.1-nano-2025-04-14\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.137\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel openai/gpt-4.1-nano-2025-04-14 with prompt achieved score: 9.0000, Correct: 9, Incorrect: 1, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.137\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/gemma2-9b-it\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.143\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/gemma2-9b-it with prompt achieved score: 7.0000, Correct: 7, Incorrect: 3, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.143\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_outputs\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGetting outputs for 10 rows using groq/qwen-qwq-32b\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.147\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mget_scores\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1mCalculated 10 scores\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.base\u001b[0m:\u001b[36mcalculate_scores\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel groq/qwen-qwq-32b with prompt achieved score: 9.0000, Correct: 9, Incorrect: 1, Unlabelled: 0 out of 10\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.148\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[32m\u001b[1mTraining complete. Best overall model is groq/qwen-qwq-32b. Final test score: 9.0000\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mSaving final best prompt (based on test set).\u001b[0m\n",
      "\u001b[32m2025-05-12 21:49:27.149\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtaskllm.optimizer.methods.bayesian\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m100\u001b[0m - \u001b[32m\u001b[1mSuccessfully saved best prompt and config.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "await trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b2ad86-80f5-42ab-9379-568a95ae932b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
